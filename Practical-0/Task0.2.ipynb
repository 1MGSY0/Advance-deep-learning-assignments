{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>**AlexNet training**<u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning:\n",
    "- Use AlexNet\n",
    "- Initialize it with random weights\n",
    "- Train the entire model on CIFAR-10\n",
    "\n",
    "### Feature Extraction:\n",
    "- Use pretrained AlexNet\n",
    "- Freeze all layers except the final classifier\n",
    "- Replace final layer with a Linear(4096, 10) layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform for AlexNet input (224x224)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # AlexNet expects 224x224 input\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing and downloading the CIFAR-10 dataset\n",
    "data_path = './data'\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    trainSet = torchvision.datasets.CIFAR10(root=data_path, train=True,\n",
    "                                            download=True, transform=transform)\n",
    "    testSet = torchvision.datasets.CIFAR10(root=data_path, train=False,\n",
    "                                           download=True, transform=transform)\n",
    "else:\n",
    "    trainSet = torchvision.datasets.CIFAR10(root=data_path, train=True,\n",
    "                                            download=False, transform=transform)\n",
    "    testSet = torchvision.datasets.CIFAR10(root=data_path, train=False,\n",
    "                                           download=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_alexnet(pretrained=False, feature_extract=False):\n",
    "    model = models.alexnet(pretrained=pretrained)\n",
    "    \n",
    "    # Replace the last FC layer with 10 outputs\n",
    "    num_features = model.classifier[6].in_features\n",
    "    model.classifier[6] = nn.Linear(num_features, 10)\n",
    "\n",
    "    # Freeze all layers except final classifier if using feature extraction\n",
    "    if feature_extract:\n",
    "        for param in model.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    return model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, criterion, loader, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        progress = tqdm(loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=True, ncols=100)\n",
    "\n",
    "        for inputs, labels in progress:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            progress.set_postfix(loss=loss.item())\n",
    "        print(f\"Epoch {epoch+1} complete — avg loss: {running_loss/len(loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    progress = tqdm(loader, desc=\"Evaluating\", leave=True, ncols=100)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in progress:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            acc = 100 * correct / total\n",
    "            progress.set_postfix(accuracy=f\"{acc:.2f}%\")\n",
    "\n",
    "    final_acc = 100 * correct / total\n",
    "    print(f\"Final Test Accuracy: {final_acc:.2f}%\")\n",
    "    return final_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning AlexNet (no pretraining)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|████████████████████████████████████████| 782/782 [01:01<00:00, 12.70it/s, loss=1.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 complete — avg loss: 1.6865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████████████████████████████████| 782/782 [01:03<00:00, 12.38it/s, loss=0.918]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 complete — avg loss: 1.3368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|███████████████████████████████████████| 782/782 [01:06<00:00, 11.78it/s, loss=1.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 complete — avg loss: 1.2063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|███████████████████████████████████████| 782/782 [01:07<00:00, 11.61it/s, loss=1.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 complete — avg loss: 1.0934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|███████████████████████████████████████| 782/782 [01:07<00:00, 11.66it/s, loss=1.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 complete — avg loss: 1.0169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████| 157/157 [00:14<00:00, 10.71it/s, accuracy=66.03%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 66.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66.03"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft = modify_alexnet(pretrained=False)\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"Fine-Tuning AlexNet (no pretraining)...\")\n",
    "train_model(model_ft, optimizer_ft, criterion, trainloader, epochs=5)\n",
    "evaluate_model(model_ft, testloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gushi\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to C:\\Users\\gushi/.cache\\torch\\hub\\checkpoints\\alexnet-owt-7be5be79.pth\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 233M/233M [00:21<00:00, 11.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Extraction with Pretrained AlexNet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████████████████████████████████| 782/782 [00:50<00:00, 15.52it/s, loss=0.566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 complete — avg loss: 0.8644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████████████████████████████████| 782/782 [00:48<00:00, 16.10it/s, loss=0.946]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 complete — avg loss: 0.6767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████████████████████████████████| 782/782 [00:49<00:00, 15.71it/s, loss=0.746]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 complete — avg loss: 0.6215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████████████████████████████████| 782/782 [00:50<00:00, 15.48it/s, loss=0.391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 complete — avg loss: 0.5733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|███████████████████████████████████████| 782/782 [00:49<00:00, 15.85it/s, loss=0.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 complete — avg loss: 0.5423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████| 157/157 [00:14<00:00, 10.97it/s, accuracy=82.62%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 82.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82.62"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fe = modify_alexnet(pretrained=True, feature_extract=True)\n",
    "optimizer_fe = optim.Adam(filter(lambda p: p.requires_grad, model_fe.parameters()), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"Feature Extraction with Pretrained AlexNet...\")\n",
    "train_model(model_fe, optimizer_fe, criterion, trainloader, epochs=5)\n",
    "evaluate_model(model_fe, testloader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
